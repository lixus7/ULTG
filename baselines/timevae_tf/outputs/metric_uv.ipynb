{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), './'))\n",
    "from Utils.context_fid import Context_FID\n",
    "from Utils.metric_utils import display_scores\n",
    "from Utils.cross_correlation import CrossCorrelLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading  Morning Peak\n",
    "\n",
    "Load original dataset and preprocess the loaded data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori shape is:  (2881, 24, 7)\n",
      "fake shape is:  (2881, 24, 7)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 3-dimensional, but 4 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mori shape is: \u001b[39m\u001b[38;5;124m'\u001b[39m, ori_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfake shape is: \u001b[39m\u001b[38;5;124m'\u001b[39m, fake_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 18\u001b[0m fake_data \u001b[38;5;241m=\u001b[39m \u001b[43mfake_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     19\u001b[0m b,t,n \u001b[38;5;241m=\u001b[39m fake_data\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# ori_data = ori_data.transpose(2, 0, 1).reshape(b * n, t, 1)\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 3-dimensional, but 4 were indexed"
     ]
    }
   ],
   "source": [
    "# iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# # ori_data = np.load('../OUTPUT/{dataset_name}/samples/{dataset_name}_norm_truth_{seq_length}_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../toy_exp/ddpm_fake_sines.npy')\n",
    "\n",
    "\n",
    "iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# ori_data = np.load('../OUTPUT/test_ep/samples/etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../OUTPUT/test_ep/ddpm_fake_test_ep_milestone_10.npy')\n",
    "\n",
    "ori_data = np.load('./etth_mp/ori_etth_mp24.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "fake_data = np.load('./etth_mp/generate_etth_mp24.npy')\n",
    " \n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)\n",
    "\n",
    "b,t,n = fake_data.shape\n",
    "# ori_data = ori_data.transpose(2, 0, 1).reshape(b * n, t, 1)\n",
    "# fake_data = fake_data.transpose(2, 0, 1).reshape(b * n, t, 1)\n",
    "\n",
    "# ori_data = ori_data[:fake_data.shape[0]*fake_data.shape[2]]\n",
    "# fake_data = fake_data.reshape(n, b, t).transpose(1, 2, 0)\n",
    "\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Context-FID Score\n",
    "\n",
    "- The Frechet Inception distance-like score is based on unsupervised time series embeddings. It is able to score the fit of the fixed length synthetic samples into their context of (often much longer) true time series.\n",
    "\n",
    "- The lowest scoring models correspond to the best performing models in downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  context-fid = 1.6986284536257041 \n",
      "\n",
      "Iter 1:  context-fid = 2.2373361566673706 \n",
      "\n",
      "Iter 2:  context-fid = 2.3729883231429136 \n",
      "\n",
      "Iter 3:  context-fid = 2.0512278936608124 \n",
      "\n",
      "Iter 4:  context-fid = 1.8356401974279053 \n",
      "\n",
      "Final Score:  2.0391642049049414 ± 0.34468356449967946\n",
      "Iter 0:  context-fid = 2.072091546076176 \n",
      "\n",
      "Iter 1:  context-fid = 1.3325190142330492 \n",
      "\n",
      "Iter 2:  context-fid = 2.0348614532719984 \n",
      "\n",
      "Iter 3:  context-fid = 2.0578781936449184 \n",
      "\n",
      "Iter 4:  context-fid = 2.015397234938828 \n",
      "\n",
      "Final Score:  1.902549488432994 ± 0.3965786793717447\n",
      "Iter 0:  context-fid = 2.040920051533032 \n",
      "\n",
      "Iter 1:  context-fid = 0.8115768304522557 \n",
      "\n",
      "Iter 2:  context-fid = 0.8772127509612841 \n",
      "\n",
      "Iter 3:  context-fid = 2.5617460359990387 \n",
      "\n",
      "Iter 4:  context-fid = 1.3817423317699058 \n",
      "\n",
      "Final Score:  1.5346396001431033 ± 0.9394226088265512\n"
     ]
    }
   ],
   "source": [
    "for j in range(3):\n",
    "\n",
    "    context_fid_score = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        context_fid = Context_FID(ori_data[:], fake_data[:ori_data.shape[0]])\n",
    "        context_fid_score.append(context_fid)\n",
    "        print(f'Iter {i}: ', 'context-fid =', context_fid, '\\n')\n",
    "\n",
    "    display_scores(context_fid_score)\n",
    "\n",
    "# Seed 12345 :  mp  10mile  0.292   0.309\n",
    "# seed 12345 :  ep  10mile  0.151\n",
    "\n",
    "\n",
    "# uncondi   2.3  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '../'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "from Utils.metric_utils import display_scores\n",
    "from Utils.discriminative_metric import discriminative_score_metrics\n",
    "from Utils.predictive_metric import predictive_score_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Morning Peak\n",
    "\n",
    "Load original dataset and preprocess the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori shape is:  (2880, 24, 7)\n",
      "fake shape is:  (2880, 24, 7)\n",
      "ori shape is:  (20160, 24, 1)\n",
      "fake shape is:  (20160, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "# iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# # ori_data = np.load('../OUTPUT/{dataset_name}/samples/{dataset_name}_norm_truth_{seq_length}_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../toy_exp/ddpm_fake_sines.npy')\n",
    "\n",
    "\n",
    "iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# ori_data = np.load('../OUTPUT/test_ep/samples/etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../OUTPUT/test_ep/ddpm_fake_test_ep_milestone_10.npy')\n",
    "\n",
    "ori_data = np.load('./etth_mp/ori_etth_mp24.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "fake_data = np.load('./etth_mp/generate_etth_mp24.npy')\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)\n",
    "b,t,n = ori_data.shape\n",
    "\n",
    "\n",
    "ori_data = ori_data.transpose(2, 0, 1).reshape(b * n, t, 1)\n",
    "fake_data = fake_data.transpose(2, 0, 1).reshape(b * n, t, 1)\n",
    "\n",
    "# fake_data = fake_data[:ori_data.shape[0]*ori_data.shape[2]]\n",
    "# fake_data = fake_data.reshape(n, b, t).transpose(1, 2, 0)\n",
    "\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the generated data\n",
    "\n",
    "### 1. Discriminative score\n",
    "\n",
    "To evaluate the classification accuracy between original and synthetic data using post-hoc RNN network. The output is | classification accuracy - 0.5 |.\n",
    "\n",
    "- metric_iteration: the number of iterations for metric computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch/duyin/test/tsge/difftsunivariate/Experiments/../Utils/discriminative_metric.py:101: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /mnt/data728/duyin/anaconda3/envs/torch201/lib/python3.9/site-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:579: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /mnt/data728/duyin/anaconda3/envs/torch201/lib/python3.9/site-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:589: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /scratch/duyin/test/tsge/difftsunivariate/Experiments/../Utils/discriminative_metric.py:105: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [01:01<00:00, 32.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  0.017026578073089715 , 0.48518826135105203 , 0.5488648947951273 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:58<00:00, 34.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1:  0.00567552602436322 , 0.5170957918050941 , 0.4715531561461794 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:56<00:00, 35.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 2:  0.012423864894795134 , 0.46047895902547065 , 0.5146733111849391 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:56<00:00, 35.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 3:  0.007405869324473957 , 0.6319905869324474 , 0.38282115171650055 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 2000/2000 [00:52<00:00, 37.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 4:  0.015053986710963474 , 0.5393133997785161 , 0.49079457364341084 \n",
      "\n",
      "etth:\n",
      "Final Score:  0.0115171650055371 ± 0.0060419535687656544\n",
      "\n"
     ]
    }
   ],
   "source": [
    "discriminative_score = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    temp_disc, fake_acc, real_acc = discriminative_score_metrics(ori_data[:], fake_data[:ori_data.shape[0]])\n",
    "    discriminative_score.append(temp_disc)\n",
    "    print(f'Iter {i}: ', temp_disc, ',', fake_acc, ',', real_acc, '\\n')\n",
    "      \n",
    "print('etth:')\n",
    "display_scores(discriminative_score)\n",
    "print()\n",
    "# seed 12345  Final Score:  0.0731896551724138 ± 0.005795392020461213\n",
    "# seed 2024  Final Score:  0.06945402298850574 ± 0.010002021083688875\n",
    "\n",
    "# univariate Final Score:  0.004115022310361938 ± 0.003740431320553614\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the generated data\n",
    "\n",
    "### 2. Predictive score\n",
    "\n",
    "To evaluate the prediction performance on train on synthetic, test on real setting. More specifically, we use Post-hoc RNN architecture to predict one-step ahead and report the performance in terms of MAE. \n",
    "\n",
    "The model learns to predict the last dimension with one more step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch/duyin/test/tsge/difftsunivariate/Experiments/../Utils/predictive_metric.py:75: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /mnt/data728/duyin/anaconda3/envs/torch201/lib/python3.9/site-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:579: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /mnt/data728/duyin/anaconda3/envs/torch201/lib/python3.9/site-packages/keras/layers/legacy_rnn/rnn_cell_impl.py:589: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /scratch/duyin/test/tsge/difftsunivariate/Experiments/../Utils/predictive_metric.py:79: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 5000/5000 [01:50<00:00, 45.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  epoch:  0.2036337936773948 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 5000/5000 [01:48<00:00, 46.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  epoch:  0.20367806120860535 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 5000/5000 [01:55<00:00, 43.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2  epoch:  0.2037564074033652 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 5000/5000 [01:48<00:00, 45.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3  epoch:  0.20367786735220364 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training: 100%|██████████| 5000/5000 [01:52<00:00, 44.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4  epoch:  0.20359909053625458 \n",
      "\n",
      "sine:\n",
      "Final Score:  0.2036690440355647 ± 7.326764080408571e-05\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictive_score = []\n",
    "for i in range(iterations):\n",
    "    temp_pred = predictive_score_metrics(ori_data, fake_data[:ori_data.shape[0]])\n",
    "    predictive_score.append(temp_pred)\n",
    "    print(i, ' epoch: ', temp_pred, '\\n')\n",
    "      \n",
    "print('sine:')\n",
    "display_scores(predictive_score)\n",
    "print()\n",
    "\n",
    "# univariate Final Score:  0.1605687830457955 ± 3.0256014600636085e-05"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch201",
   "language": "python",
   "name": "torch201"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
