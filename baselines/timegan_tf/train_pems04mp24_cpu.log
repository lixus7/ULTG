nohup: ignoring input
WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.
ori_data shape is  (2183, 307)
pems04_mp dataset is ready.
ori_data [0] shape is:  (24, 1)
ori_data save shape is:  (663120, 24, 1)
pems04_mp dataset is saved.
Start Embedding Network Training
step: 0/50000, e_loss: 0.2348
step: 1000/50000, e_loss: 0.0065
step: 2000/50000, e_loss: 0.004
step: 3000/50000, e_loss: 0.0072
step: 4000/50000, e_loss: 0.0039
step: 5000/50000, e_loss: 0.0061
step: 6000/50000, e_loss: 0.0047
step: 7000/50000, e_loss: 0.0036
step: 8000/50000, e_loss: 0.0045
step: 9000/50000, e_loss: 0.0027
step: 10000/50000, e_loss: 0.0038
step: 11000/50000, e_loss: 0.0032
step: 12000/50000, e_loss: 0.0028
step: 13000/50000, e_loss: 0.0047
step: 14000/50000, e_loss: 0.0024
step: 15000/50000, e_loss: 0.0028
step: 16000/50000, e_loss: 0.0031
step: 17000/50000, e_loss: 0.0016
step: 18000/50000, e_loss: 0.0024
step: 19000/50000, e_loss: 0.002
step: 20000/50000, e_loss: 0.0012
step: 21000/50000, e_loss: 0.0029
step: 22000/50000, e_loss: 0.0022
step: 23000/50000, e_loss: 0.0022
step: 24000/50000, e_loss: 0.002
step: 25000/50000, e_loss: 0.0029
step: 26000/50000, e_loss: 0.0024
step: 27000/50000, e_loss: 0.0024
step: 28000/50000, e_loss: 0.0021
step: 29000/50000, e_loss: 0.0025
step: 30000/50000, e_loss: 0.0023
step: 31000/50000, e_loss: 0.0023
step: 32000/50000, e_loss: 0.0016
step: 33000/50000, e_loss: 0.0025
step: 34000/50000, e_loss: 0.0034
step: 35000/50000, e_loss: 0.0024
step: 36000/50000, e_loss: 0.0013
step: 37000/50000, e_loss: 0.002
step: 38000/50000, e_loss: 0.0019
step: 39000/50000, e_loss: 0.0016
step: 40000/50000, e_loss: 0.0027
step: 41000/50000, e_loss: 0.0025
step: 42000/50000, e_loss: 0.0016
step: 43000/50000, e_loss: 0.0011
step: 44000/50000, e_loss: 0.0027
step: 45000/50000, e_loss: 0.0016
step: 46000/50000, e_loss: 0.0019
step: 47000/50000, e_loss: 0.002
step: 48000/50000, e_loss: 0.0012
step: 49000/50000, e_loss: 0.0018
Finish Embedding Network Training
Start Training with Supervised Loss Only
step: 0/50000, s_loss: 0.33
step: 1000/50000, s_loss: 0.1027
step: 2000/50000, s_loss: 0.1015
step: 3000/50000, s_loss: 0.0945
step: 4000/50000, s_loss: 0.097
step: 5000/50000, s_loss: 0.092
step: 6000/50000, s_loss: 0.0941
step: 7000/50000, s_loss: 0.0993
step: 8000/50000, s_loss: 0.0908
step: 9000/50000, s_loss: 0.0928
step: 10000/50000, s_loss: 0.0959
step: 11000/50000, s_loss: 0.0966
step: 12000/50000, s_loss: 0.0971
step: 13000/50000, s_loss: 0.0899
step: 14000/50000, s_loss: 0.0965
step: 15000/50000, s_loss: 0.0872
step: 16000/50000, s_loss: 0.0965
step: 17000/50000, s_loss: 0.0991
step: 18000/50000, s_loss: 0.0945
step: 19000/50000, s_loss: 0.0971
step: 20000/50000, s_loss: 0.0938
step: 21000/50000, s_loss: 0.0951
step: 22000/50000, s_loss: 0.0975
step: 23000/50000, s_loss: 0.0946
step: 24000/50000, s_loss: 0.0953
step: 25000/50000, s_loss: 0.0929
step: 26000/50000, s_loss: 0.0916
step: 27000/50000, s_loss: 0.0914
step: 28000/50000, s_loss: 0.092
step: 29000/50000, s_loss: 0.097
step: 30000/50000, s_loss: 0.088
step: 31000/50000, s_loss: 0.0978
step: 32000/50000, s_loss: 0.0971
step: 33000/50000, s_loss: 0.0981
step: 34000/50000, s_loss: 0.0953
step: 35000/50000, s_loss: 0.0948
step: 36000/50000, s_loss: 0.0979
step: 37000/50000, s_loss: 0.0982
step: 38000/50000, s_loss: 0.0929
step: 39000/50000, s_loss: 0.0936
step: 40000/50000, s_loss: 0.0941
step: 41000/50000, s_loss: 0.0934
step: 42000/50000, s_loss: 0.0905
step: 43000/50000, s_loss: 0.0934
step: 44000/50000, s_loss: 0.0919
step: 45000/50000, s_loss: 0.0923
step: 46000/50000, s_loss: 0.0928
step: 47000/50000, s_loss: 0.0909
step: 48000/50000, s_loss: 0.0985
step: 49000/50000, s_loss: 0.0923
Finish Training with Supervised Loss Only
Start Joint Training
step: 0/50000, d_loss: 2.122, g_loss_u: 0.6208, g_loss_s: 0.0992, g_loss_v: 0.2535, e_loss_t0: 0.031
step: 1000/50000, d_loss: 0.9521, g_loss_u: 1.5834, g_loss_s: 0.1004, g_loss_v: 0.0432, e_loss_t0: 0.0015
step: 2000/50000, d_loss: 1.4655, g_loss_u: 1.2406, g_loss_s: 0.094, g_loss_v: 0.0159, e_loss_t0: 0.0014
step: 3000/50000, d_loss: 1.6756, g_loss_u: 1.2365, g_loss_s: 0.0914, g_loss_v: 0.0546, e_loss_t0: 0.0024
step: 4000/50000, d_loss: 1.6219, g_loss_u: 1.4332, g_loss_s: 0.0899, g_loss_v: 0.0212, e_loss_t0: 0.0015
step: 5000/50000, d_loss: 1.4941, g_loss_u: 1.5158, g_loss_s: 0.0802, g_loss_v: 0.0181, e_loss_t0: 0.0018
step: 6000/50000, d_loss: 1.4735, g_loss_u: 1.3206, g_loss_s: 0.0869, g_loss_v: 0.0261, e_loss_t0: 0.0022
step: 7000/50000, d_loss: 1.5133, g_loss_u: 1.3034, g_loss_s: 0.083, g_loss_v: 0.0329, e_loss_t0: 0.0013
step: 8000/50000, d_loss: 1.5368, g_loss_u: 1.395, g_loss_s: 0.0792, g_loss_v: 0.0265, e_loss_t0: 0.0014
step: 9000/50000, d_loss: 1.4926, g_loss_u: 1.413, g_loss_s: 0.083, g_loss_v: 0.0861, e_loss_t0: 0.0018
step: 10000/50000, d_loss: 1.6572, g_loss_u: 1.1753, g_loss_s: 0.0824, g_loss_v: 0.0805, e_loss_t0: 0.0017
step: 11000/50000, d_loss: 1.5193, g_loss_u: 1.3039, g_loss_s: 0.0783, g_loss_v: 0.021, e_loss_t0: 0.0017
step: 12000/50000, d_loss: 1.5472, g_loss_u: 1.3959, g_loss_s: 0.0802, g_loss_v: 0.023, e_loss_t0: 0.0026
step: 13000/50000, d_loss: 1.5615, g_loss_u: 1.3309, g_loss_s: 0.0806, g_loss_v: 0.0245, e_loss_t0: 0.0015
step: 14000/50000, d_loss: 1.5432, g_loss_u: 1.4188, g_loss_s: 0.0783, g_loss_v: 0.0222, e_loss_t0: 0.0018
step: 15000/50000, d_loss: 1.6329, g_loss_u: 1.271, g_loss_s: 0.0742, g_loss_v: 0.0355, e_loss_t0: 0.0015
step: 16000/50000, d_loss: 1.7029, g_loss_u: 1.4188, g_loss_s: 0.0803, g_loss_v: 0.0287, e_loss_t0: 0.0013
step: 17000/50000, d_loss: 1.6537, g_loss_u: 1.2115, g_loss_s: 0.0793, g_loss_v: 0.0518, e_loss_t0: 0.0015
step: 18000/50000, d_loss: 1.5308, g_loss_u: 1.4332, g_loss_s: 0.0778, g_loss_v: 0.0281, e_loss_t0: 0.0014
step: 19000/50000, d_loss: 1.6562, g_loss_u: 1.3184, g_loss_s: 0.0754, g_loss_v: 0.0478, e_loss_t0: 0.0016
step: 20000/50000, d_loss: 1.4807, g_loss_u: 1.2953, g_loss_s: 0.0743, g_loss_v: 0.0331, e_loss_t0: 0.0012
step: 21000/50000, d_loss: 1.6609, g_loss_u: 1.3443, g_loss_s: 0.0751, g_loss_v: 0.0368, e_loss_t0: 0.001
step: 22000/50000, d_loss: 1.5187, g_loss_u: 1.3932, g_loss_s: 0.0738, g_loss_v: 0.0438, e_loss_t0: 0.0018
step: 23000/50000, d_loss: 1.5976, g_loss_u: 1.382, g_loss_s: 0.0765, g_loss_v: 0.035, e_loss_t0: 0.0013
step: 24000/50000, d_loss: 1.6844, g_loss_u: 1.2693, g_loss_s: 0.0818, g_loss_v: 0.0325, e_loss_t0: 0.0015
step: 25000/50000, d_loss: 1.6405, g_loss_u: 1.266, g_loss_s: 0.0741, g_loss_v: 0.0464, e_loss_t0: 0.0015
step: 26000/50000, d_loss: 1.6386, g_loss_u: 1.3618, g_loss_s: 0.0728, g_loss_v: 0.0938, e_loss_t0: 0.0006
step: 27000/50000, d_loss: 1.5854, g_loss_u: 1.343, g_loss_s: 0.0748, g_loss_v: 0.0232, e_loss_t0: 0.0017
step: 28000/50000, d_loss: 1.6691, g_loss_u: 1.3679, g_loss_s: 0.074, g_loss_v: 0.0259, e_loss_t0: 0.0014
step: 29000/50000, d_loss: 1.6822, g_loss_u: 1.1525, g_loss_s: 0.0736, g_loss_v: 0.0276, e_loss_t0: 0.0011
step: 30000/50000, d_loss: 1.6246, g_loss_u: 1.3941, g_loss_s: 0.0718, g_loss_v: 0.0393, e_loss_t0: 0.0017
step: 31000/50000, d_loss: 1.6092, g_loss_u: 1.2604, g_loss_s: 0.0727, g_loss_v: 0.021, e_loss_t0: 0.0014
step: 32000/50000, d_loss: 1.4672, g_loss_u: 1.2495, g_loss_s: 0.0724, g_loss_v: 0.0419, e_loss_t0: 0.0004
step: 33000/50000, d_loss: 1.5536, g_loss_u: 1.4168, g_loss_s: 0.0712, g_loss_v: 0.0182, e_loss_t0: 0.002
step: 34000/50000, d_loss: 1.5122, g_loss_u: 1.4209, g_loss_s: 0.0761, g_loss_v: 0.0251, e_loss_t0: 0.0012
step: 35000/50000, d_loss: 1.6535, g_loss_u: 1.4274, g_loss_s: 0.0683, g_loss_v: 0.037, e_loss_t0: 0.0017
step: 36000/50000, d_loss: 1.5659, g_loss_u: 1.299, g_loss_s: 0.0704, g_loss_v: 0.0211, e_loss_t0: 0.0013
step: 37000/50000, d_loss: 1.5806, g_loss_u: 1.2274, g_loss_s: 0.0705, g_loss_v: 0.0221, e_loss_t0: 0.0008
step: 38000/50000, d_loss: 1.5655, g_loss_u: 1.2973, g_loss_s: 0.0679, g_loss_v: 0.0232, e_loss_t0: 0.0015
step: 39000/50000, d_loss: 1.451, g_loss_u: 1.4136, g_loss_s: 0.0734, g_loss_v: 0.0336, e_loss_t0: 0.0017
step: 40000/50000, d_loss: 1.5863, g_loss_u: 1.3296, g_loss_s: 0.0686, g_loss_v: 0.0466, e_loss_t0: 0.0011
step: 41000/50000, d_loss: 1.5627, g_loss_u: 1.285, g_loss_s: 0.0652, g_loss_v: 0.0536, e_loss_t0: 0.0013
step: 42000/50000, d_loss: 1.5801, g_loss_u: 1.313, g_loss_s: 0.0685, g_loss_v: 0.0943, e_loss_t0: 0.0012
step: 43000/50000, d_loss: 1.5072, g_loss_u: 1.1688, g_loss_s: 0.0723, g_loss_v: 0.0506, e_loss_t0: 0.0014
step: 44000/50000, d_loss: 1.5374, g_loss_u: 1.4587, g_loss_s: 0.0684, g_loss_v: 0.0626, e_loss_t0: 0.0018
step: 45000/50000, d_loss: 1.5558, g_loss_u: 1.2644, g_loss_s: 0.0701, g_loss_v: 0.0253, e_loss_t0: 0.0006
step: 46000/50000, d_loss: 1.6124, g_loss_u: 1.2314, g_loss_s: 0.0697, g_loss_v: 0.0245, e_loss_t0: 0.0012
step: 47000/50000, d_loss: 1.6215, g_loss_u: 1.4672, g_loss_s: 0.068, g_loss_v: 0.0296, e_loss_t0: 0.0013
step: 48000/50000, d_loss: 1.6779, g_loss_u: 1.1919, g_loss_s: 0.072, g_loss_v: 0.0338, e_loss_t0: 0.001
step: 49000/50000, d_loss: 1.6335, g_loss_u: 1.4945, g_loss_s: 0.0622, g_loss_v: 0.0404, e_loss_t0: 0.0011
Finish Joint Training
Finish Synthetic Data Generation
generated_data shape is  (663120, 24, 1)
Finished saving generated data pems04_mp
[t-SNE] Computing 121 nearest neighbors...
[t-SNE] Indexed 2000 samples in 0.010s...
/mnt/data728/duyin/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/neighbors/base.py:441: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  old_joblib = LooseVersion(joblib_version) < LooseVersion('0.12')
/mnt/data728/duyin/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/neighbors/base.py:441: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
  old_joblib = LooseVersion(joblib_version) < LooseVersion('0.12')
[t-SNE] Computed neighbors for 2000 samples in 0.314s...
[t-SNE] Computed conditional probabilities for sample 1000 / 2000
[t-SNE] Computed conditional probabilities for sample 2000 / 2000
[t-SNE] Mean sigma: 0.179784
[t-SNE] KL divergence after 250 iterations with early exaggeration: 65.680534
[t-SNE] KL divergence after 300 iterations: 1.409917
{'discriminative': 0.02573553806249247, 'predictive': 0.17686188093956418}
Total execution time: 53570.70 seconds
