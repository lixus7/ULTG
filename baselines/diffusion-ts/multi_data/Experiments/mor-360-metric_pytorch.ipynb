{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-FID Score Presentation\n",
    "## Necessary packages and functions call\n",
    "\n",
    "- Context-FID score: A useful metric measures how well the the synthetic time series windows ”fit” into the local context of the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T13:20:59.954749Z",
     "start_time": "2025-01-19T13:20:56.940593Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '../'))\n",
    "from Utils.context_fid import Context_FID\n",
    "from Utils.metric_utils import display_scores\n",
    "from Utils.cross_correlation import CrossCorrelLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load original dataset and preprocess the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T13:20:59.968547Z",
     "start_time": "2025-01-19T13:20:59.958214Z"
    }
   },
   "outputs": [],
   "source": [
    "# iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# # ori_data = np.load('../OUTPUT/{dataset_name}/samples/{dataset_name}_norm_truth_{seq_length}_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../toy_exp/ddpm_fake_sines.npy')\n",
    "\n",
    "\n",
    "iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "ori_data = np.load('../OUTPUT/test/samples/morning_peak_etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "fake_data = np.load('../OUTPUT/test/ddpm_fake_morning_peak_etth_milestone_1000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori shape is:  (2881, 24, 7)\n",
      "fake shape is:  (3600, 24, 7)\n"
     ]
    }
   ],
   "source": [
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context-FID Score\n",
    "\n",
    "- The Frechet Inception distance-like score is based on unsupervised time series embeddings. It is able to score the fit of the fixed length synthetic samples into their context of (often much longer) true time series.\n",
    "\n",
    "- The lowest scoring models correspond to the best performing models in downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T13:57:01.485538Z",
     "start_time": "2025-01-19T13:20:59.971210Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data728/duyin/anaconda3/envs/torch201/lib/python3.9/site-packages/torch/nn/modules/conv.py:309: UserWarning: Applied workaround for CuDNN issue, install nvrtc.so (Triggered internally at /opt/conda/conda-bld/pytorch_1682343997789/work/aten/src/ATen/native/cudnn/Conv_v8.cpp:80.)\n",
      "  return F.conv1d(input, weight, bias, self.stride,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  context-fid = 0.25906747324115403 \n",
      "\n",
      "Iter 1:  context-fid = 0.2933629537594794 \n",
      "\n",
      "Iter 2:  context-fid = 0.28260160660836453 \n",
      "\n",
      "Iter 3:  context-fid = 0.29062610840063285 \n",
      "\n",
      "Iter 4:  context-fid = 0.28430485379894793 \n",
      "\n",
      "Final Score:  0.2819925991617157 ± 0.016832463275340992\n",
      "Iter 0:  context-fid = 0.30897270475322347 \n",
      "\n",
      "Iter 1:  context-fid = 0.26985096079599513 \n",
      "\n",
      "Iter 2:  context-fid = 0.2894612259710446 \n",
      "\n",
      "Iter 3:  context-fid = 0.2769913049817549 \n",
      "\n",
      "Iter 4:  context-fid = 0.2654812027399775 \n",
      "\n",
      "Final Score:  0.28215147984839917 ± 0.02176136871458309\n",
      "Iter 0:  context-fid = 0.2719209582662512 \n",
      "\n",
      "Iter 1:  context-fid = 0.29380294800932927 \n",
      "\n",
      "Iter 2:  context-fid = 0.28245384941378127 \n",
      "\n",
      "Iter 3:  context-fid = 0.2716057679803626 \n",
      "\n",
      "Iter 4:  context-fid = 0.26794041372508337 \n",
      "\n",
      "Final Score:  0.27754478747896155 ± 0.01313422991756374\n",
      "Iter 0:  context-fid = 0.3119169718703485 \n",
      "\n",
      "Iter 1:  context-fid = 0.2526349257152799 \n",
      "\n",
      "Iter 2:  context-fid = 0.29707991480082574 \n",
      "\n",
      "Iter 3:  context-fid = 0.3053410473941037 \n",
      "\n",
      "Iter 4:  context-fid = 0.32361537985951444 \n",
      "\n",
      "Final Score:  0.29811764792801443 ± 0.03379110544007905\n",
      "Iter 0:  context-fid = 0.2589560079737079 \n",
      "\n",
      "Iter 1:  context-fid = 0.24957019204540337 \n",
      "\n",
      "Iter 2:  context-fid = 0.26389369326450574 \n",
      "\n",
      "Iter 3:  context-fid = 0.3274852344574032 \n",
      "\n",
      "Iter 4:  context-fid = 0.2529244260908993 \n",
      "\n",
      "Final Score:  0.2705659107663839 ± 0.04009613522662355\n",
      "Iter 0:  context-fid = 0.2826711275809942 \n",
      "\n",
      "Iter 1:  context-fid = 0.28821837945833867 \n",
      "\n",
      "Iter 2:  context-fid = 0.26020490567368415 \n",
      "\n",
      "Iter 3:  context-fid = 0.2710412190331505 \n",
      "\n",
      "Iter 4:  context-fid = 0.26166688377675656 \n",
      "\n",
      "Final Score:  0.27276050310458483 ± 0.015468982942743592\n",
      "Iter 0:  context-fid = 0.27130496519494046 \n",
      "\n",
      "Iter 1:  context-fid = 0.27176903155246024 \n",
      "\n",
      "Iter 2:  context-fid = 0.25011189127103994 \n",
      "\n",
      "Iter 3:  context-fid = 0.30491936977295503 \n",
      "\n",
      "Iter 4:  context-fid = 0.24651722202907703 \n",
      "\n",
      "Final Score:  0.2689244959640945 ± 0.028889634957544038\n",
      "Iter 0:  context-fid = 0.26745992572347765 \n",
      "\n",
      "Iter 1:  context-fid = 0.2746007459974712 \n",
      "\n",
      "Iter 2:  context-fid = 0.3074761980467878 \n",
      "\n",
      "Iter 3:  context-fid = 0.2611521838242504 \n",
      "\n",
      "Iter 4:  context-fid = 0.3161582619829954 \n",
      "\n",
      "Final Score:  0.28536946311499645 ± 0.03079133500094341\n",
      "Iter 0:  context-fid = 0.29358140967976026 \n",
      "\n",
      "Iter 1:  context-fid = 0.28087903666988817 \n",
      "\n",
      "Iter 2:  context-fid = 0.2691456470318251 \n",
      "\n",
      "Iter 3:  context-fid = 0.2982646575116806 \n",
      "\n",
      "Iter 4:  context-fid = 0.2682607575165946 \n",
      "\n",
      "Final Score:  0.28202630168194975 ± 0.01704658621125578\n",
      "Iter 0:  context-fid = 0.29430003169017477 \n",
      "\n",
      "Iter 1:  context-fid = 0.2821775166071499 \n",
      "\n",
      "Iter 2:  context-fid = 0.2970036800150439 \n",
      "\n",
      "Iter 3:  context-fid = 0.2573792443234454 \n",
      "\n",
      "Iter 4:  context-fid = 0.23644018690000648 \n",
      "\n",
      "Final Score:  0.27346013190716406 ± 0.03222150462686319\n"
     ]
    }
   ],
   "source": [
    "for j in range(10):\n",
    "\n",
    "    context_fid_score = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        context_fid = Context_FID(ori_data[:], fake_data[:ori_data.shape[0]])\n",
    "        context_fid_score.append(context_fid)\n",
    "        print(f'Iter {i}: ', 'context-fid =', context_fid, '\\n')\n",
    "\n",
    "    display_scores(context_fid_score)\n",
    "\n",
    "# single mp input, 360epoch,   0.354\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlational Score\n",
    "\n",
    "- The metric uses the absolute error of the auto-correlation estimator by real data and synthetic data as the metric to assess the temporal dependency.\n",
    "\n",
    "- For d > 1, it uses the l1-norm of the difference between cross correlation matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T13:57:01.499575Z",
     "start_time": "2025-01-19T13:57:01.493562Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_choice(size, num_select=100):\n",
    "    select_idx = np.random.randint(low=0, high=size, size=(num_select,))\n",
    "    return select_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T13:57:01.622099Z",
     "start_time": "2025-01-19T13:57:01.502760Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  cross-correlation = 0.11397961049790839 \n",
      "\n",
      "Iter 1:  cross-correlation = 0.11904152512068163 \n",
      "\n",
      "Iter 2:  cross-correlation = 0.04847594380661483 \n",
      "\n",
      "Iter 3:  cross-correlation = 0.09386066591843291 \n",
      "\n",
      "Iter 4:  cross-correlation = 0.09537706316327271 \n",
      "\n",
      "Final Score:  0.09414696170138209 ± 0.03456930737114451\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "x_real = torch.from_numpy(ori_data)\n",
    "x_fake = torch.from_numpy(fake_data)\n",
    "\n",
    "correlational_score = []\n",
    "size = int(x_real.shape[0] / iterations)\n",
    "\n",
    "for i in range(iterations):\n",
    "    real_idx = random_choice(x_real.shape[0], size)\n",
    "    fake_idx = random_choice(x_fake.shape[0], size)\n",
    "    corr = CrossCorrelLoss(x_real[real_idx, :, :], name='CrossCorrelLoss')\n",
    "    loss = corr.compute(x_fake[fake_idx, :, :])\n",
    "    correlational_score.append(loss.item())\n",
    "    print(f'Iter {i}: ', 'cross-correlation =', loss.item(), '\\n')\n",
    "\n",
    "display_scores(correlational_score)\n",
    "\n",
    "# double input, 0.181\n",
    "# single input  mp, 360 epoch,    0.084 + 0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch201",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
