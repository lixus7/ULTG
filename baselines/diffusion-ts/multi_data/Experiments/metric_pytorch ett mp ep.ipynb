{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-FID Score Presentation\n",
    "## Necessary packages and functions call\n",
    "\n",
    "- Context-FID score: A useful metric measures how well the the synthetic time series windows ”fit” into the local context of the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:05:16.594392Z",
     "start_time": "2024-11-11T16:05:13.793428Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '../'))\n",
    "from Utils.context_fid import Context_FID\n",
    "from Utils.metric_utils import display_scores\n",
    "from Utils.cross_correlation import CrossCorrelLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading  Morning Peak\n",
    "\n",
    "Load original dataset and preprocess the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:05:16.633192Z",
     "start_time": "2024-11-11T16:05:16.597089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori shape is:  (2881, 24, 7)\n",
      "fake shape is:  (20700, 24, 1)\n",
      "ori shape is:  (20167, 24, 1)\n",
      "fake shape is:  (20700, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "# iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# # ori_data = np.load('../OUTPUT/{dataset_name}/samples/{dataset_name}_norm_truth_{seq_length}_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../toy_exp/ddpm_fake_sines.npy')\n",
    "\n",
    "\n",
    "iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# ori_data = np.load('../OUTPUT/test_ep/samples/etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../OUTPUT/test_ep/ddpm_fake_test_ep_milestone_10.npy')\n",
    "\n",
    "ori_data = np.load('../OUTPUT/etth_mpep/samples/morning_peak_etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "fake_data = np.load('../OUTPUT/etth_mpep/ddpm_fake_morning_peak_etth_milestone_500.npy')\n",
    "\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)\n",
    "b,t,n = ori_data.shape\n",
    "\n",
    "\n",
    "ori_data = ori_data.transpose(2, 0, 1).reshape(b * n, t, 1)\n",
    "\n",
    "# fake_data = fake_data[:ori_data.shape[0]*ori_data.shape[2]]\n",
    "# fake_data = fake_data.reshape(n, b, t).transpose(1, 2, 0)\n",
    "\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Context-FID Score\n",
    "\n",
    "- The Frechet Inception distance-like score is based on unsupervised time series embeddings. It is able to score the fit of the fixed length synthetic samples into their context of (often much longer) true time series.\n",
    "\n",
    "- The lowest scoring models correspond to the best performing models in downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:35:19.971852Z",
     "start_time": "2024-11-11T16:05:16.635200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  context-fid = 0.10202260536765614 \n",
      "\n",
      "Iter 1:  context-fid = 0.09069351036866274 \n",
      "\n",
      "Iter 2:  context-fid = 0.0998399036499504 \n",
      "\n",
      "Iter 3:  context-fid = 0.11043615429809825 \n",
      "\n",
      "Iter 4:  context-fid = 0.08376089242374185 \n",
      "\n",
      "Final Score:  0.09735061322162189 ± 0.01284766773866546\n",
      "Iter 0:  context-fid = 0.08768118198323899 \n",
      "\n",
      "Iter 1:  context-fid = 0.09008245031905535 \n",
      "\n",
      "Iter 2:  context-fid = 0.09328211804942788 \n",
      "\n",
      "Iter 3:  context-fid = 0.12893061594702643 \n",
      "\n",
      "Iter 4:  context-fid = 0.12215831471610569 \n",
      "\n",
      "Final Score:  0.10442693620297086 ± 0.024246042205174866\n",
      "Iter 0:  context-fid = 0.1009398038946919 \n",
      "\n",
      "Iter 1:  context-fid = 0.13728129345551981 \n",
      "\n",
      "Iter 2:  context-fid = 0.09482702397469475 \n",
      "\n",
      "Iter 3:  context-fid = 0.10773269500828958 \n",
      "\n",
      "Iter 4:  context-fid = 0.09805075323734214 \n",
      "\n",
      "Final Score:  0.10776631391410763 ± 0.02132224638743598\n"
     ]
    }
   ],
   "source": [
    "for j in range(3):\n",
    "\n",
    "    context_fid_score = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        context_fid = Context_FID(ori_data[:], fake_data[:ori_data.shape[0]])\n",
    "        context_fid_score.append(context_fid)\n",
    "        print(f'Iter {i}: ', 'context-fid =', context_fid, '\\n')\n",
    "\n",
    "    display_scores(context_fid_score)\n",
    "\n",
    "# Seed 12345 :  mp  10mile  0.292   0.309\n",
    "# seed 12345 :  ep  10mile  0.151\n",
    "\n",
    "\n",
    "# mp 24  mix etth mpep input,   \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlational Score\n",
    "\n",
    "- The metric uses the absolute error of the auto-correlation estimator by real data and synthetic data as the metric to assess the temporal dependency.\n",
    "\n",
    "- For d > 1, it uses the l1-norm of the difference between cross correlation matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:35:19.979030Z",
     "start_time": "2024-11-11T16:35:19.975068Z"
    }
   },
   "outputs": [],
   "source": [
    "def random_choice(size, num_select=100):\n",
    "    select_idx = np.random.randint(low=0, high=size, size=(num_select,))\n",
    "    return select_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:35:20.130211Z",
     "start_time": "2024-11-11T16:35:19.980968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  cross-correlation = 1.432187701766452e-15 \n",
      "\n",
      "Iter 1:  cross-correlation = 1.4099832412739487e-15 \n",
      "\n",
      "Iter 2:  cross-correlation = 1.2323475573339237e-15 \n",
      "\n",
      "Iter 3:  cross-correlation = 2.930988785010413e-15 \n",
      "\n",
      "Iter 4:  cross-correlation = 7.216449660063518e-16 \n",
      "\n",
      "Final Score:  1.5454304502782177e-15 ± 1.0253290331335782e-15\n"
     ]
    }
   ],
   "source": [
    "x_real = torch.from_numpy(ori_data)\n",
    "x_fake = torch.from_numpy(fake_data)\n",
    "\n",
    "correlational_score = []\n",
    "size = int(x_real.shape[0] / iterations)\n",
    "\n",
    "for i in range(iterations):\n",
    "    real_idx = random_choice(x_real.shape[0], size)\n",
    "    fake_idx = random_choice(x_fake.shape[0], size)\n",
    "    corr = CrossCorrelLoss(x_real[real_idx, :, :], name='CrossCorrelLoss')\n",
    "    loss = corr.compute(x_fake[fake_idx, :, :])\n",
    "    correlational_score.append(loss.item())\n",
    "    print(f'Iter {i}: ', 'cross-correlation =', loss.item(), '\\n')\n",
    "\n",
    "display_scores(correlational_score)\n",
    "\n",
    "# single input    mp 10miles    0.087 + 0.02\n",
    "# single input    ep 10miles    0.104 + 0.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Evening Peak\n",
    "\n",
    "Load original dataset and preprocess the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori shape is:  (2880, 24, 7)\n",
      "fake shape is:  (20700, 24, 1)\n",
      "ori shape is:  (20160, 24, 1)\n",
      "fake shape is:  (20700, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "# iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# # ori_data = np.load('../OUTPUT/{dataset_name}/samples/{dataset_name}_norm_truth_{seq_length}_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../toy_exp/ddpm_fake_sines.npy')\n",
    "\n",
    "\n",
    "iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# ori_data = np.load('../OUTPUT/test_ep/samples/etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../OUTPUT/test_ep/ddpm_fake_test_ep_milestone_10.npy')\n",
    "\n",
    "ori_data = np.load('../OUTPUT/etth_mpep/samples/evening_peak_etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "fake_data = np.load('../OUTPUT/etth_mpep/ddpm_fake_evening_peak_etth_milestone_500.npy')\n",
    "\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)\n",
    "b,t,n = ori_data.shape\n",
    "\n",
    "\n",
    "ori_data = ori_data.transpose(2, 0, 1).reshape(b * n, t, 1)\n",
    "\n",
    "# fake_data = fake_data[:ori_data.shape[0]*ori_data.shape[2]]\n",
    "# fake_data = fake_data.reshape(n, b, t).transpose(1, 2, 0)\n",
    "\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Context-FID Score\n",
    "\n",
    "- The Frechet Inception distance-like score is based on unsupervised time series embeddings. It is able to score the fit of the fixed length synthetic samples into their context of (often much longer) true time series.\n",
    "\n",
    "- The lowest scoring models correspond to the best performing models in downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  context-fid = 0.04408167500634456 \n",
      "\n",
      "Iter 1:  context-fid = 0.028713816672307654 \n",
      "\n",
      "Iter 2:  context-fid = 0.043102472912550274 \n",
      "\n",
      "Iter 3:  context-fid = 0.04024633937982867 \n",
      "\n",
      "Iter 4:  context-fid = 0.043523238015058974 \n",
      "\n",
      "Final Score:  0.03993350839721803 ± 0.008001634029997184\n",
      "Iter 0:  context-fid = 0.0339054057788801 \n",
      "\n",
      "Iter 1:  context-fid = 0.027146468529383953 \n",
      "\n",
      "Iter 2:  context-fid = 0.03908637152651748 \n",
      "\n",
      "Iter 3:  context-fid = 0.03896425899266845 \n",
      "\n",
      "Iter 4:  context-fid = 0.04202412330468053 \n",
      "\n",
      "Final Score:  0.0362253256264261 ± 0.0072698623462340165\n",
      "Iter 0:  context-fid = 0.05322801443432249 \n",
      "\n",
      "Iter 1:  context-fid = 0.03567782327446088 \n",
      "\n",
      "Iter 2:  context-fid = 0.04932337001794816 \n",
      "\n",
      "Iter 3:  context-fid = 0.04830015896868775 \n",
      "\n",
      "Iter 4:  context-fid = 0.02307292187508076 \n",
      "\n",
      "Final Score:  0.04192045771410001 ± 0.015428201434468249\n"
     ]
    }
   ],
   "source": [
    "for j in range(3):\n",
    "\n",
    "    context_fid_score = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        context_fid = Context_FID(ori_data[:], fake_data[:ori_data.shape[0]])\n",
    "        context_fid_score.append(context_fid)\n",
    "        print(f'Iter {i}: ', 'context-fid =', context_fid, '\\n')\n",
    "\n",
    "    display_scores(context_fid_score)\n",
    "\n",
    "# Seed 12345 :  mp  10mile  0.292   0.309\n",
    "# seed 12345 :  ep  10mile  0.151\n",
    "\n",
    "\n",
    "# mp 24 是0.047， 96 就0.2了应该，但是gpt的24是0.02\n",
    "\n",
    "#  ep 24 是  0.0123\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlational Score\n",
    "\n",
    "- The metric uses the absolute error of the auto-correlation estimator by real data and synthetic data as the metric to assess the temporal dependency.\n",
    "\n",
    "- For d > 1, it uses the l1-norm of the difference between cross correlation matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_choice(size, num_select=100):\n",
    "    select_idx = np.random.randint(low=0, high=size, size=(num_select,))\n",
    "    return select_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  cross-correlation = 1.5321077739827161e-15 \n",
      "\n",
      "Iter 1:  cross-correlation = 1.4988010832439613e-15 \n",
      "\n",
      "Iter 2:  cross-correlation = 2.253752739989068e-15 \n",
      "\n",
      "Iter 3:  cross-correlation = 3.519406988061746e-15 \n",
      "\n",
      "Iter 4:  cross-correlation = 5.329070518200751e-16 \n",
      "\n",
      "Final Score:  1.8673951274195133e-15 ± 1.37532897420109e-15\n"
     ]
    }
   ],
   "source": [
    "x_real = torch.from_numpy(ori_data)\n",
    "x_fake = torch.from_numpy(fake_data)\n",
    "\n",
    "correlational_score = []\n",
    "size = int(x_real.shape[0] / iterations)\n",
    "\n",
    "for i in range(iterations):\n",
    "    real_idx = random_choice(x_real.shape[0], size)\n",
    "    fake_idx = random_choice(x_fake.shape[0], size)\n",
    "    corr = CrossCorrelLoss(x_real[real_idx, :, :], name='CrossCorrelLoss')\n",
    "    loss = corr.compute(x_fake[fake_idx, :, :])\n",
    "    correlational_score.append(loss.item())\n",
    "    print(f'Iter {i}: ', 'cross-correlation =', loss.item(), '\\n')\n",
    "\n",
    "display_scores(correlational_score)\n",
    "\n",
    "# single input    mp 10miles    0.087 + 0.02\n",
    "# single input    ep 10miles    0.104 + 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch201",
   "language": "python",
   "name": "torch201"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
