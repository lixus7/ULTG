{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context-FID Score Presentation\n",
    "## Necessary packages and functions call\n",
    "\n",
    "- Context-FID score: A useful metric measures how well the the synthetic time series windows ”fit” into the local context of the time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:05:16.594392Z",
     "start_time": "2024-11-11T16:05:13.793428Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname('__file__'), '../'))\n",
    "from Utils.context_fid import Context_FID\n",
    "from Utils.metric_utils import display_scores\n",
    "from Utils.cross_correlation import CrossCorrelLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading  Morning Peak\n",
    "\n",
    "Load original dataset and preprocess the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-11T16:05:16.633192Z",
     "start_time": "2024-11-11T16:05:16.597089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori shape is:  (2881, 24, 7)\n",
      "fake shape is:  (20700, 24, 1)\n",
      "ori shape is:  (20167, 24, 1)\n",
      "fake shape is:  (20700, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "# iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# # ori_data = np.load('../OUTPUT/{dataset_name}/samples/{dataset_name}_norm_truth_{seq_length}_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../toy_exp/ddpm_fake_sines.npy')\n",
    "\n",
    "\n",
    "iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# ori_data = np.load('../OUTPUT/test_ep/samples/etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../OUTPUT/test_ep/ddpm_fake_test_ep_milestone_10.npy')\n",
    "\n",
    "ori_data = np.load('../OUTPUT/etth_mp/samples/etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "fake_data = np.load('../OUTPUT/etth_mp/ddpm_fake_etth_mp_milestone_10.npy')\n",
    "\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)\n",
    "b,t,n = ori_data.shape\n",
    "\n",
    "\n",
    "ori_data = ori_data.transpose(2, 0, 1).reshape(b * n, t, 1)\n",
    "\n",
    "# fake_data = fake_data[:ori_data.shape[0]*ori_data.shape[2]]\n",
    "# fake_data = fake_data.reshape(n, b, t).transpose(1, 2, 0)\n",
    "\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)\n",
    "\n",
    "for j in range(2):\n",
    "\n",
    "    context_fid_score = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        context_fid = Context_FID(ori_data[:], fake_data[:ori_data.shape[0]])\n",
    "        context_fid_score.append(context_fid)\n",
    "        print(f'Iter {i}: ', 'context-fid =', context_fid, '\\n')\n",
    "\n",
    "    display_scores(context_fid_score)\n",
    "\n",
    "# Seed 12345 :  mp  10mile  0.292   0.309\n",
    "# seed 12345 :  ep  10mile  0.151\n",
    "\n",
    "\n",
    "# mp 24 是0.047， 96 就0.2了应该，但是gpt的24是0.02\n",
    "\n",
    "#  ep 24 是  0.0127\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading Evening Peak\n",
    "\n",
    "Load original dataset and preprocess the loaded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ori shape is:  (2880, 24, 7)\n",
      "fake shape is:  (20384, 24, 1)\n",
      "ori shape is:  (20160, 24, 1)\n",
      "fake shape is:  (20384, 24, 1)\n"
     ]
    }
   ],
   "source": [
    "# iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# # ori_data = np.load('../OUTPUT/{dataset_name}/samples/{dataset_name}_norm_truth_{seq_length}_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../toy_exp/ddpm_fake_sines.npy')\n",
    "\n",
    "\n",
    "iterations = 5\n",
    "# ori_data = np.load('../toy_exp/samples/sine_ground_truth_24_train.npy')\n",
    "# ori_data = np.load('../OUTPUT/test_ep/samples/etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "# fake_data = np.load('../OUTPUT/test_ep/ddpm_fake_test_ep_milestone_10.npy')\n",
    "\n",
    "ori_data = np.load('../OUTPUT/etth_ep/samples/etth_norm_truth_24_train.npy')  # Uncomment the line if dataset other than Sine is used.\n",
    "fake_data = np.load('../OUTPUT/etth_ep/ddpm_fake_etth_ep_milestone_10.npy')\n",
    "\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)\n",
    "b,t,n = ori_data.shape\n",
    "\n",
    "\n",
    "ori_data = ori_data.transpose(2, 0, 1).reshape(b * n, t, 1)\n",
    "\n",
    "# fake_data = fake_data[:ori_data.shape[0]*ori_data.shape[2]]\n",
    "# fake_data = fake_data.reshape(n, b, t).transpose(1, 2, 0)\n",
    "\n",
    "print('ori shape is: ', ori_data.shape)\n",
    "print('fake shape is: ', fake_data.shape)\n",
    "\n",
    "for j in range(2):\n",
    "\n",
    "    context_fid_score = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "        context_fid = Context_FID(ori_data[:], fake_data[:ori_data.shape[0]])\n",
    "        context_fid_score.append(context_fid)\n",
    "        print(f'Iter {i}: ', 'context-fid =', context_fid, '\\n')\n",
    "\n",
    "    display_scores(context_fid_score)\n",
    "\n",
    "# Seed 12345 :  mp  10mile  0.292   0.309\n",
    "# seed 12345 :  ep  10mile  0.151\n",
    "\n",
    "\n",
    "# mp 24 是0.047， 96 就0.2了应该，但是gpt的24是0.02\n",
    "\n",
    "#  ep 24 是  0.0123\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Context-FID Score\n",
    "\n",
    "- The Frechet Inception distance-like score is based on unsupervised time series embeddings. It is able to score the fit of the fixed length synthetic samples into their context of (often much longer) true time series.\n",
    "\n",
    "- The lowest scoring models correspond to the best performing models in downstream tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0:  context-fid = 0.010801204008179384 \n",
      "\n",
      "Iter 1:  context-fid = 0.013182236687175341 \n",
      "\n",
      "Iter 2:  context-fid = 0.013469286113870185 \n",
      "\n",
      "Iter 3:  context-fid = 0.01318728388631028 \n",
      "\n",
      "Iter 4:  context-fid = 0.010585620545841726 \n",
      "\n",
      "Final Score:  0.012245126248275385 ± 0.001767276008017265\n",
      "Iter 0:  context-fid = 0.012405038600340455 \n",
      "\n",
      "Iter 1:  context-fid = 0.012721212628880034 \n",
      "\n",
      "Iter 2:  context-fid = 0.011190600911776835 \n",
      "\n",
      "Iter 3:  context-fid = 0.01394747381858677 \n",
      "\n",
      "Iter 4:  context-fid = 0.012656352862423958 \n",
      "\n",
      "Final Score:  0.012584135764401611 ± 0.001219221614261294\n",
      "Iter 0:  context-fid = 0.013622022727071331 \n",
      "\n",
      "Iter 1:  context-fid = 0.013990621104866891 \n",
      "\n",
      "Iter 2:  context-fid = 0.01132609248966804 \n",
      "\n",
      "Iter 3:  context-fid = 0.010317602668542723 \n",
      "\n",
      "Iter 4:  context-fid = 0.014674956687430421 \n",
      "\n",
      "Final Score:  0.012786259135515881 ± 0.0023181669292001907\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch201",
   "language": "python",
   "name": "torch201"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
